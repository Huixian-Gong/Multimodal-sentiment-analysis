{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e2ff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/huixian/.conda/envs/multiood/lib/python3.12/site-packages/transformers/models/videomae/feature_extraction_videomae.py:28: FutureWarning: The class VideoMAEFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use VideoMAEImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11.7665\n",
      "Val Loss: 12.0621\n",
      "Macro-F1: 0.2997 | Micro-F1: 0.3689 | Acc: 0.3689 | Recall: [0.2125     0.89855072 0.05263158]\n",
      "✅ Best model saved at epoch 0 with Macro-F1=0.2997\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11.4028\n",
      "Val Loss: 11.6766\n",
      "Macro-F1: 0.3971 | Micro-F1: 0.4133 | Acc: 0.4133 | Recall: [0.45       0.61594203 0.19078947]\n",
      "✅ Best model saved at epoch 1 with Macro-F1=0.3971\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 11.1734\n",
      "Val Loss: 11.4754\n",
      "Macro-F1: 0.4296 | Micro-F1: 0.4311 | Acc: 0.4311 | Recall: [0.30625 0.5     0.5    ]\n",
      "✅ Best model saved at epoch 2 with Macro-F1=0.4296\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.9261\n",
      "Val Loss: 11.2209\n",
      "Macro-F1: 0.4289 | Micro-F1: 0.4267 | Acc: 0.4267 | Recall: [0.43125    0.43478261 0.41447368]\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.7432\n",
      "Val Loss: 11.1692\n",
      "Macro-F1: 0.4206 | Micro-F1: 0.4200 | Acc: 0.4200 | Recall: [0.40625    0.39130435 0.46052632]\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.5980\n",
      "Val Loss: 11.0889\n",
      "Macro-F1: 0.4313 | Micro-F1: 0.4333 | Acc: 0.4333 | Recall: [0.43125    0.35507246 0.50657895]\n",
      "✅ Best model saved at epoch 5 with Macro-F1=0.4313\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.4883\n",
      "Val Loss: 11.1947\n",
      "Macro-F1: 0.4284 | Micro-F1: 0.4400 | Acc: 0.4400 | Recall: [0.35625    0.3115942  0.64473684]\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.3804\n",
      "Val Loss: 11.1523\n",
      "Macro-F1: 0.4172 | Micro-F1: 0.4289 | Acc: 0.4289 | Recall: [0.60625    0.29710145 0.36184211]\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.2244\n",
      "Val Loss: 11.0572\n",
      "Macro-F1: 0.4284 | Micro-F1: 0.4356 | Acc: 0.4356 | Recall: [0.54375    0.30434783 0.44078947]\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.1068\n",
      "Val Loss: 10.9891\n",
      "Macro-F1: 0.4440 | Micro-F1: 0.4511 | Acc: 0.4511 | Recall: [0.4875     0.3115942  0.53947368]\n",
      "✅ Best model saved at epoch 9 with Macro-F1=0.4440\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 10.0732\n",
      "Val Loss: 10.8857\n",
      "Macro-F1: 0.4345 | Micro-F1: 0.4422 | Acc: 0.4422 | Recall: [0.425      0.3115942  0.57894737]\n",
      "\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.9403\n",
      "Val Loss: 11.3333\n",
      "Macro-F1: 0.4368 | Micro-F1: 0.4600 | Acc: 0.4600 | Recall: [0.7125     0.26086957 0.375     ]\n",
      "\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.8569\n",
      "Val Loss: 11.0528\n",
      "Macro-F1: 0.4312 | Micro-F1: 0.4444 | Acc: 0.4444 | Recall: [0.5875     0.26086957 0.46052632]\n",
      "\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.8074\n",
      "Val Loss: 10.8989\n",
      "Macro-F1: 0.4116 | Micro-F1: 0.4289 | Acc: 0.4289 | Recall: [0.425     0.2173913 0.625    ]\n",
      "\n",
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.6556\n",
      "Val Loss: 10.7950\n",
      "Macro-F1: 0.4327 | Micro-F1: 0.4422 | Acc: 0.4422 | Recall: [0.475      0.2826087  0.55263158]\n",
      "\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.5826\n",
      "Val Loss: 10.8635\n",
      "Macro-F1: 0.4148 | Micro-F1: 0.4311 | Acc: 0.4311 | Recall: [0.44375    0.22463768 0.60526316]\n",
      "\n",
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.4668\n",
      "Val Loss: 10.7020\n",
      "Macro-F1: 0.4215 | Micro-F1: 0.4378 | Acc: 0.4378 | Recall: [0.45625    0.22463768 0.61184211]\n",
      "\n",
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.4391\n",
      "Val Loss: 10.7567\n",
      "Macro-F1: 0.4309 | Micro-F1: 0.4444 | Acc: 0.4444 | Recall: [0.575      0.24637681 0.48684211]\n",
      "\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.3177\n",
      "Val Loss: 10.7192\n",
      "Macro-F1: 0.4328 | Micro-F1: 0.4444 | Acc: 0.4444 | Recall: [0.5375     0.26086957 0.51315789]\n",
      "\n",
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.2719\n",
      "Val Loss: 10.7338\n",
      "Macro-F1: 0.4511 | Micro-F1: 0.4622 | Acc: 0.4622 | Recall: [0.5125     0.2826087  0.57236842]\n",
      "✅ Best model saved at epoch 19 with Macro-F1=0.4511\n",
      "\n",
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.1568\n",
      "Val Loss: 10.6500\n",
      "Macro-F1: 0.4354 | Micro-F1: 0.4556 | Acc: 0.4556 | Recall: [0.4625     0.22463768 0.65789474]\n",
      "\n",
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 9.1017\n",
      "Val Loss: 10.5852\n",
      "Macro-F1: 0.4368 | Micro-F1: 0.4556 | Acc: 0.4556 | Recall: [0.46875    0.23188406 0.64473684]\n",
      "\n",
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.9937\n",
      "Val Loss: 10.7506\n",
      "Macro-F1: 0.4546 | Micro-F1: 0.4733 | Acc: 0.4733 | Recall: [0.65       0.25362319 0.48684211]\n",
      "✅ Best model saved at epoch 22 with Macro-F1=0.4546\n",
      "\n",
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.9146\n",
      "Val Loss: 10.8559\n",
      "Macro-F1: 0.4648 | Micro-F1: 0.4822 | Acc: 0.4822 | Recall: [0.66875    0.2826087  0.46710526]\n",
      "✅ Best model saved at epoch 23 with Macro-F1=0.4648\n",
      "\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 8.8437\n",
      "Val Loss: 10.8135\n",
      "Macro-F1: 0.4470 | Micro-F1: 0.4667 | Acc: 0.4667 | Recall: [0.6625     0.24637681 0.46052632]\n",
      "\n",
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 207\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m     train_loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     val_loss, val_preds, val_labels \u001b[38;5;241m=\u001b[39m run_epoch(regressor, val_loader, optimizer, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    210\u001b[0m     macro_f1, micro_f1, recall, acc \u001b[38;5;241m=\u001b[39m evaluate(val_preds, val_labels)\n",
      "Cell \u001b[0;32mIn[1], line 137\u001b[0m, in \u001b[0;36mrun_epoch\u001b[0;34m(model, loader, optimizer, is_train)\u001b[0m\n\u001b[1;32m    134\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    135\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 137\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m total_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m    139\u001b[0m total_labels\u001b[38;5;241m.\u001b[39mextend(targets\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "gpu_ids = [4]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, gpu_ids))\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import VideoMAEFeatureExtractor, VideoMAEModel\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- SETTINGS ----\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "negative_samples = 1500\n",
    "neutral_samples = 1500\n",
    "positive_samples = 1500\n",
    "batch_size = 16\n",
    "clip_len = 16\n",
    "num_epochs = 30\n",
    "\n",
    "clip_dir = \"/data/home/huixian/Documents/Homeworks/535_project/MOSEI/Clip/Clips_16frames\"\n",
    "mapping_csv = \"/data/home/huixian/Documents/Homeworks/535_project/MOSEI/Clip/clip_sentiment_mapping.csv\"\n",
    "\n",
    "# ---- DATASET ----\n",
    "class VideoClipDataset(Dataset):\n",
    "    def __init__(self, clip_dir, csv_path, feature_extractor):\n",
    "        self.clip_dir = clip_dir\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.feature_extractor = feature_extractor\n",
    "\n",
    "        # Map filename to (sentiment_score, sentiment_label)\n",
    "        self.filename2score = dict()\n",
    "        for _, row in self.df.iterrows():\n",
    "            clip_name = row[\"clip_filename\"]\n",
    "            score = row[\"sentiment_score\"]\n",
    "            label = row[\"sentiment_label\"]\n",
    "            self.filename2score[clip_name] = (score, label)\n",
    "\n",
    "        # Group by label\n",
    "        self.grouped = {\"Negative\": [], \"Neutral\": [], \"Positive\": []}\n",
    "        for clip_name, (_, label) in self.filename2score.items():\n",
    "            self.grouped[label].append(clip_name)\n",
    "\n",
    "        # Sample\n",
    "        sampled_neg = random.sample(self.grouped[\"Negative\"], min(len(self.grouped[\"Negative\"]), negative_samples))\n",
    "        sampled_neu = random.sample(self.grouped[\"Neutral\"], min(len(self.grouped[\"Neutral\"]), neutral_samples))\n",
    "        sampled_pos = random.sample(self.grouped[\"Positive\"], min(len(self.grouped[\"Positive\"]), positive_samples))\n",
    "        self.samples = sampled_neg + sampled_neu + sampled_pos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clip_name = self.samples[idx]\n",
    "        clip_path = os.path.join(self.clip_dir, clip_name)\n",
    "\n",
    "        cap = cv2.VideoCapture(clip_path)\n",
    "        frames = []\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frames.append(frame[:, :, ::-1])  # Convert BGR to RGB\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) < clip_len:\n",
    "            # Pad frames if too short\n",
    "            frames += [frames[-1]] * (clip_len - len(frames))\n",
    "        frames = frames[:clip_len]\n",
    "\n",
    "        inputs = self.feature_extractor(images=frames, return_tensors=\"pt\")[\"pixel_values\"].squeeze(0)  # (3, T, H, W)\n",
    "\n",
    "        sentiment_score, label = self.filename2score[clip_name]\n",
    "        return inputs, torch.tensor(sentiment_score, dtype=torch.float32)\n",
    "\n",
    "# ---- LOSS FUNCTION ----\n",
    "class CenteredWeightedMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        ideal = torch.zeros_like(targets)\n",
    "        ideal[targets < -0.3] = -3.0\n",
    "        ideal[targets > 0.3] = 3.0\n",
    "        ideal[(-0.3 <= targets) & (targets <= 0.3)] = 0.0\n",
    "\n",
    "        weights = torch.ones_like(targets)\n",
    "        weights[targets < -0.3] = 2.0\n",
    "        weights[targets > 0.3] = 2.0\n",
    "        weights[(-0.3 <= targets) & (targets <= 0.3)] = 1.0\n",
    "\n",
    "        mse = (preds - ideal) ** 2\n",
    "        return (weights * mse).mean()\n",
    "\n",
    "# ---- MODEL ----\n",
    "class SentimentRegressor(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super().__init__()\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.regressor(x).squeeze(1)\n",
    "\n",
    "# ---- TRAINING LOOP ----\n",
    "def run_epoch(model, loader, optimizer, is_train=True):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    total_loss = 0\n",
    "\n",
    "    for clips, targets in tqdm(loader, leave=False):\n",
    "        clips = clips.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        with torch.set_grad_enabled(is_train):\n",
    "            features = video_mae(clips).last_hidden_state.mean(dim=1)  # Global average pooling\n",
    "            preds = model(features)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_preds.extend(preds.detach().cpu().numpy())\n",
    "        total_labels.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    return avg_loss, np.array(total_preds), np.array(total_labels)\n",
    "\n",
    "def evaluate(preds, labels):\n",
    "    preds_label = []\n",
    "    labels_label = []\n",
    "\n",
    "    for p in preds:\n",
    "        if p < -0.3:\n",
    "            preds_label.append(\"Negative\")\n",
    "        elif p > 0.3:\n",
    "            preds_label.append(\"Positive\")\n",
    "        else:\n",
    "            preds_label.append(\"Neutral\")\n",
    "\n",
    "    for l in labels:\n",
    "        if l < -0.3:\n",
    "            labels_label.append(\"Negative\")\n",
    "        elif l > 0.3:\n",
    "            labels_label.append(\"Positive\")\n",
    "        else:\n",
    "            labels_label.append(\"Neutral\")\n",
    "\n",
    "    macro_f1 = f1_score(labels_label, preds_label, average=\"macro\")\n",
    "    micro_f1 = f1_score(labels_label, preds_label, average=\"micro\")\n",
    "    recall = recall_score(labels_label, preds_label, average=None, labels=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "    acc = accuracy_score(labels_label, preds_label)\n",
    "\n",
    "    return macro_f1, micro_f1, recall, acc\n",
    "\n",
    "# ---- LOAD EVERYTHING ----\n",
    "feature_extractor = VideoMAEFeatureExtractor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "video_mae = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\").to(device)\n",
    "video_mae.eval()  # Freeze VideoMAE\n",
    "for param in video_mae.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "dataset = VideoClipDataset(\n",
    "    clip_dir=clip_dir,\n",
    "    csv_path=mapping_csv,\n",
    "    feature_extractor=feature_extractor\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "regressor = SentimentRegressor(feature_dim=768).to(device)\n",
    "loss_fn = CenteredWeightedMSELoss()\n",
    "optimizer = optim.Adam(regressor.parameters(), lr=2e-4)\n",
    "\n",
    "# ---- TRAIN ----\n",
    "best_macro_f1 = -np.inf\n",
    "start_epoch = 0\n",
    "# model_path = \"/data/home/huixian/Documents/Homeworks/535_project/mosei_code/best_regressor.pth\"\n",
    "# if os.path.exists(model_path):\n",
    "#     regressor.load_state_dict(torch.load(model_path))\n",
    "#     start_epoch = 15  # Replace X with last completed epoch + 1\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"\\nEpoch {epoch}\")\n",
    "\n",
    "    train_loss, _, _ = run_epoch(regressor, train_loader, optimizer, is_train=True)\n",
    "    val_loss, val_preds, val_labels = run_epoch(regressor, val_loader, optimizer, is_train=False)\n",
    "\n",
    "    macro_f1, micro_f1, recall, acc = evaluate(val_preds, val_labels)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"Macro-F1: {macro_f1:.4f} | Micro-F1: {micro_f1:.4f} | Acc: {acc:.4f} | Recall: {recall}\")\n",
    "\n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        torch.save(regressor.state_dict(), \"best_regressor_epo_30_bs_16_lr_2e-4.pth\")\n",
    "        print(f\"✅ Best model saved at epoch {epoch} with Macro-F1={macro_f1:.4f}\")\n",
    "\n",
    "# ---- EVALUATE ON TEST SET ----\n",
    "test_loss, test_preds, test_labels = run_epoch(regressor, test_loader, optimizer, is_train=False)\n",
    "macro_f1, micro_f1, recall, acc = evaluate(test_preds, test_labels)\n",
    "print(\"\\n----- TEST RESULTS -----\")\n",
    "print(f\"Macro-F1: {macro_f1:.4f} | Micro-F1: {micro_f1:.4f} | Acc: {acc:.4f} | Recall: {recall}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
